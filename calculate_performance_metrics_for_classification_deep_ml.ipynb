{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "implement function that computes various performance metrics for a binary classification problem. These metrics include:\n",
        "confusion matrix\n",
        "accuracy\n",
        "F1 score\n",
        "specificity\n",
        "negative predictive value\n",
        "The function should take in two lists:\n",
        "The actual class labels 1 for positive and 0 for negative\n",
        "the predicted class labels from the model\n",
        "and the function should return a tuple containing\n",
        "confusion matrix: A 2*2 matrix\n",
        "accuracy: a float representing the F1 score of the model\n",
        "specificity: A float representing the specificoty of the model\n",
        "negative_predictive_value: A float representing the negative predictive value\n",
        "The function calculates the confusion matrix, accuracy, f1 score, specificity, and negative predictive value based on the input label. the resulting values are rounded to three decimal places are required."
      ],
      "metadata": {
        "id": "HWEcS6Y46Gj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def performance_metrics(actual,predicted):\n",
        "  #with counter\n",
        "  from collections import Counter\n",
        "  data=list(zip(actual,predicted)) #zip([1,0,1],[[0,0,1]])->([1,0],[0,0],[1,1])\n",
        "  counts=Counter(tuple(pair) for pair in data) #counter is a dictionary and dictionary cant have list as key so we convert to tuple and it counts the pairs in the data\n",
        "  TP,TN,FP,FN=counts[(1,1)],counts[(0,0)],counts[(0,1)],counts[(1,0)]\n",
        "  #with numpy\n",
        "  # actual=np.array(actual)\n",
        "  # predicted=np.array(predicted)\n",
        "  # #confusion matrix\n",
        "  # TP=np.sum((actual==1) & (predicted==1))\n",
        "  # TN=np.sum((actual==0) & (predicted==0))\n",
        "  # FP=np.sum((actual==0) & (predicted==1))\n",
        "  # FN=np.sum((actual==1) & (predicted==0))\n",
        "  confusion_matrix=[[TP,FN],[FP, TN]]\n",
        "  #precision\n",
        "  precision=TP/(TP+FP)\n",
        "  #recall\n",
        "  recall=TP/(TP+FN)\n",
        "  #F1 score\n",
        "  F1_score=2*(precision*recall)/(precision+recall)\n",
        "  #accuracy\n",
        "  accuracy=(TP+TN)/len(predicted)\n",
        "  #specificity\n",
        "  specificity=TN/(TN+FP)\n",
        "  #negative predictive value\n",
        "  NPV=TN/(TN+FN)\n",
        "  return [confusion_matrix,round(accuracy,3),round(F1_score,3),round(specificity,3),round(NPV,3)]\n",
        "  # return [np.round(confusion_matrix,3).tolist(),np.round(accuracy,3),np.round(F1_score,3),np.round(specificity,3),np.round(NPV,3)]"
      ],
      "metadata": {
        "id": "oZ0G2IvY98iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMephT-Axb-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d0b326-5520-4c6f-b84d-f7ce17bac3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[2, 1], [1, 1]], 0.6, 0.667, 0.5, 0.5]\n"
          ]
        }
      ],
      "source": [
        "actual=[1,0,1,0,1]\n",
        "predicted=[1,0,0,1,1]\n",
        "print(performance_metrics(actual,predicted))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97XCDePPoitH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}